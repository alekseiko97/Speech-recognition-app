<?xml version="1.0" encoding="UTF-8"?>
<Bucket
   type = "1"
   version = "2.0">
   <Breakpoints>
      <BreakpointProxy
         BreakpointExtensionID = "Xcode.Breakpoint.FileBreakpoint">
         <BreakpointContent
            shouldBeEnabled = "Yes"
            ignoreCount = "0"
            continueAfterRunningActions = "No"
            filePath = "SpeechRecognition/ImageViewController.swift"
            timestampString = "570568352.430427"
            startingColumnNumber = "9223372036854775807"
            endingColumnNumber = "9223372036854775807"
            startingLineNumber = "94"
            endingLineNumber = "94"
            landmarkName = "startRecording()"
            landmarkType = "7">
            <Locations>
               <Location
                  shouldBeEnabled = "Yes"
                  ignoreCount = "0"
                  continueAfterRunningActions = "No"
                  symbolName = "SpeechRecognition.ImageViewController.startRecording() -&gt; ()"
                  moduleName = "SpeechRecognition"
                  usesParentBreakpointCondition = "Yes"
                  urlString = "file:///Users/n01353492/Documents/Speech-recognition-app/SpeechRecognition/ImageViewController.swift"
                  timestampString = "570568352.511965"
                  startingColumnNumber = "9223372036854775807"
                  endingColumnNumber = "9223372036854775807"
                  startingLineNumber = "94"
                  endingLineNumber = "94"
                  offsetFromSymbolStart = "184">
               </Location>
               <Location
                  shouldBeEnabled = "Yes"
                  ignoreCount = "0"
                  continueAfterRunningActions = "No"
                  symbolName = "closure #1 (__ObjC.AVAudioPCMBuffer, __ObjC.AVAudioTime) -&gt; () in SpeechRecognition.ImageViewController.startRecording() -&gt; ()"
                  moduleName = "SpeechRecognition"
                  usesParentBreakpointCondition = "Yes"
                  urlString = "file:///Users/n01353492/Documents/Speech-recognition-app/SpeechRecognition/ImageViewController.swift"
                  timestampString = "570568352.5140949"
                  startingColumnNumber = "9223372036854775807"
                  endingColumnNumber = "9223372036854775807"
                  startingLineNumber = "95"
                  endingLineNumber = "95"
                  offsetFromSymbolStart = "36">
               </Location>
            </Locations>
         </BreakpointContent>
      </BreakpointProxy>
      <BreakpointProxy
         BreakpointExtensionID = "Xcode.Breakpoint.FileBreakpoint">
         <BreakpointContent
            shouldBeEnabled = "Yes"
            ignoreCount = "0"
            continueAfterRunningActions = "No"
            filePath = "SpeechRecognition/ImageViewController.swift"
            timestampString = "570568352.43077"
            startingColumnNumber = "9223372036854775807"
            endingColumnNumber = "9223372036854775807"
            startingLineNumber = "92"
            endingLineNumber = "92"
            landmarkName = "startRecording()"
            landmarkType = "7">
         </BreakpointContent>
      </BreakpointProxy>
      <BreakpointProxy
         BreakpointExtensionID = "Xcode.Breakpoint.FileBreakpoint">
         <BreakpointContent
            shouldBeEnabled = "Yes"
            ignoreCount = "0"
            continueAfterRunningActions = "No"
            filePath = "SpeechRecognition/ImageViewController.swift"
            timestampString = "570568352.431018"
            startingColumnNumber = "9223372036854775807"
            endingColumnNumber = "9223372036854775807"
            startingLineNumber = "93"
            endingLineNumber = "93"
            landmarkName = "startRecording()"
            landmarkType = "7">
         </BreakpointContent>
      </BreakpointProxy>
      <BreakpointProxy
         BreakpointExtensionID = "Xcode.Breakpoint.FileBreakpoint">
         <BreakpointContent
            shouldBeEnabled = "Yes"
            ignoreCount = "0"
            continueAfterRunningActions = "No"
            filePath = "SpeechRecognition/ImageViewController.swift"
            timestampString = "570568352.431242"
            startingColumnNumber = "9223372036854775807"
            endingColumnNumber = "9223372036854775807"
            startingLineNumber = "121"
            endingLineNumber = "121"
            landmarkName = "stopRecording()"
            landmarkType = "7">
         </BreakpointContent>
      </BreakpointProxy>
      <BreakpointProxy
         BreakpointExtensionID = "Xcode.Breakpoint.FileBreakpoint">
         <BreakpointContent
            shouldBeEnabled = "Yes"
            ignoreCount = "0"
            continueAfterRunningActions = "No"
            filePath = "SpeechRecognition/ImageViewController.swift"
            timestampString = "570568352.431465"
            startingColumnNumber = "9223372036854775807"
            endingColumnNumber = "9223372036854775807"
            startingLineNumber = "122"
            endingLineNumber = "122"
            landmarkName = "stopRecording()"
            landmarkType = "7">
         </BreakpointContent>
      </BreakpointProxy>
   </Breakpoints>
</Bucket>
